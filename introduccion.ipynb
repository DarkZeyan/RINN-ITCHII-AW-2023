{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaracion e inicializacion de la red neuronal utilizando Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\anaconda\\lib\\site-packages (2.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential as seq\n",
    "from keras.layers import Conv2D as conv\n",
    "from keras.layers import MaxPooling2D as maxpool\n",
    "from keras.layers import Flatten as flat\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inciializar  Red neuronal\n",
    "classifier = seq()\n",
    "\n",
    "#Configuracion de las capas de la red\n",
    "classifier.add(\n",
    "              conv(\n",
    "              32, #cantidad de filtros que se aplicaran a la imagen\n",
    "              (3,3), #Tamano del filtro de convolucion\n",
    "              input_shape = (64,64,3), # Definir dimension de la imagen de entrada asi como sus canales de color\n",
    "              activation = 'relu'\n",
    "              )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(maxpool(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(flat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(\n",
    "    units=128, #Cantidad de neuronas en la capa\n",
    "    activation= 'relu'\n",
    "))\n",
    "\n",
    "classifier.add(Dense(\n",
    "    units=1,\n",
    "    activation = 'sigmoid'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilacion de la red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(\n",
    "    optimizer='adam',\n",
    "    loss= 'binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 2 classes.\n",
      "Found 150 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Import del set de datos.\n",
    "from keras.preprocessing.image  import ImageDataGenerator as idg\n",
    "\n",
    "train_datagen = idg(\n",
    "    rescale=1./255\n",
    ")\n",
    "test_datagen =  idg(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    './dataset/training_set_small/',                                             \n",
    "    target_size= (64,64),\n",
    "    batch_size=1,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "testing_set = test_datagen.flow_from_directory(\n",
    "    './dataset/test_set_small/',                                             \n",
    "    target_size= (64,64),\n",
    "    batch_size=1,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "  5/600 [..............................] - ETA: 1:05 - loss: 1.6536e-05 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 49s 82ms/step - loss: 3.1174e-05 - accuracy: 1.0000 - val_loss: 2.3084 - val_accuracy: 0.6267\n",
      "Epoch 2/15\n",
      "600/600 [==============================] - 48s 80ms/step - loss: 2.0852e-05 - accuracy: 1.0000 - val_loss: 2.3569 - val_accuracy: 0.6200\n",
      "Epoch 3/15\n",
      "600/600 [==============================] - 47s 79ms/step - loss: 1.3454e-05 - accuracy: 1.0000 - val_loss: 2.4131 - val_accuracy: 0.6200\n",
      "Epoch 4/15\n",
      "600/600 [==============================] - 48s 80ms/step - loss: 9.0307e-06 - accuracy: 1.0000 - val_loss: 2.4772 - val_accuracy: 0.6133\n",
      "Epoch 5/15\n",
      "600/600 [==============================] - 49s 81ms/step - loss: 6.1813e-06 - accuracy: 1.0000 - val_loss: 2.5764 - val_accuracy: 0.6200\n",
      "Epoch 6/15\n",
      "600/600 [==============================] - 48s 79ms/step - loss: 4.1216e-06 - accuracy: 1.0000 - val_loss: 2.5792 - val_accuracy: 0.5933\n",
      "Epoch 7/15\n",
      "600/600 [==============================] - 49s 82ms/step - loss: 2.8509e-06 - accuracy: 1.0000 - val_loss: 2.6414 - val_accuracy: 0.5933\n",
      "Epoch 8/15\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 2.0423e-06 - accuracy: 1.0000 - val_loss: 2.6792 - val_accuracy: 0.5933\n",
      "Epoch 9/15\n",
      "600/600 [==============================] - 51s 85ms/step - loss: 1.4420e-06 - accuracy: 1.0000 - val_loss: 2.7401 - val_accuracy: 0.5933\n",
      "Epoch 10/15\n",
      "600/600 [==============================] - 65s 109ms/step - loss: 1.0210e-06 - accuracy: 1.0000 - val_loss: 2.8108 - val_accuracy: 0.6067\n",
      "Epoch 11/15\n",
      "600/600 [==============================] - 52s 86ms/step - loss: 7.2571e-07 - accuracy: 1.0000 - val_loss: 2.8873 - val_accuracy: 0.6200\n",
      "Epoch 12/15\n",
      "600/600 [==============================] - 57s 95ms/step - loss: 5.2114e-07 - accuracy: 1.0000 - val_loss: 2.9129 - val_accuracy: 0.6067\n",
      "Epoch 13/15\n",
      "600/600 [==============================] - 52s 86ms/step - loss: 3.8631e-07 - accuracy: 1.0000 - val_loss: 2.9356 - val_accuracy: 0.5933\n",
      "Epoch 14/15\n",
      "600/600 [==============================] - 58s 97ms/step - loss: 2.8618e-07 - accuracy: 1.0000 - val_loss: 3.0106 - val_accuracy: 0.6067\n",
      "Epoch 15/15\n",
      "600/600 [==============================] - 58s 96ms/step - loss: 2.1021e-07 - accuracy: 1.0000 - val_loss: 3.0600 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x233cba02fa0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(\n",
    "    training_set, #Enviarle el set de entrenamiento\n",
    "    steps_per_epoch= len(training_set), # Definir pasos por la cantidad de imagenes que hay en el set de entrenamiento\n",
    "    epochs = 15, # Numero de ciclos de entrenamiento.\n",
    "    validation_data= testing_set, # Se le envia el test de pruebas para que pueda comparar la informacion\n",
    "    validation_steps= len(testing_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "classifier.save('./dataset/modelo_entrenado.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "classifier = load_model('./dataset/modelo_entrenado.h5')\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'perro'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val_image = image.load_img(\n",
    "    './dataset/single_prediction/cat_or_dog_1.jpg',\n",
    "    target_size=(64,64)                                 \n",
    ")\n",
    "val_image = image.img_to_array(val_image)\n",
    "\n",
    "val_image = np.expand_dims(val_image, axis=0)\n",
    "\n",
    "result = classifier.predict(val_image)\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'perro'\n",
    "else:\n",
    "    prediction = 'gato'\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
